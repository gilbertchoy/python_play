{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 9999\n",
    "pd.options.display.max_rows = 5\n",
    "mel_df = pd.read_csv('melb_data.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': [2,4,1,5,6], \n",
    "                  'col2': [3,np.NaN,4,np.NaN,6],\n",
    "                    'col3': [3,6,4,6,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1      col2  col3\n",
       "0   2.0  3.000000   3.0\n",
       "1   4.0  4.333333   6.0\n",
       "2   1.0  4.000000   4.0\n",
       "3   5.0  4.333333   6.0\n",
       "4   6.0  6.000000   2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Three ways to fix missing values:\n",
    "#1.drop column\n",
    "df1 = df.drop(['col2'], axis=1)\n",
    "#2.fill NaN fields with average\n",
    "df1 = df\n",
    "df1['col2'] = df['col2'].fillna(df['col2'].mean())\n",
    "#or\n",
    "my_imputer = SimpleImputer()\n",
    "df4 = pd.DataFrame(my_imputer.fit_transform(df)) #imputer puts mean values in NaN and removes column names\n",
    "df4.columns = df.columns #put column names back in\n",
    "df4\n",
    "#3.(BEST) fill NaN fields with average and create column for where row used to have a NaN value\n",
    "dfcopy = df\n",
    "cols_with_missing = [col for col in dfcopy.columns\n",
    "                     if dfcopy[col].isnull().any()] #create array of columns with any missing value\n",
    "for col in cols_with_missing:\n",
    "    dfcopy[col + '_was_missing'] = dfcopy[col].isnull() #create new columns \n",
    "my_imputer = SimpleImputer()\n",
    "df5 = pd.DataFrame(my_imputer.fit_transform(df))\n",
    "df5.columns = dfcopy.columns #put column names back in\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col3    0    1    2    3    4\n",
       "0     2     3  0.0  1.0  0.0  1.0  0.0\n",
       "1     4     6  1.0  0.0  0.0  0.0  1.0\n",
       "2     1     4  0.0  0.0  1.0  1.0  0.0\n",
       "3     5     6  1.0  0.0  0.0  0.0  1.0\n",
       "4     6     2  0.0  1.0  0.0  1.0  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Three ways to fix categorical data:\n",
    "\n",
    "#1. drop column\n",
    "\n",
    "#2. Label Encoding, best for Ordinal data - used for data that has ranking - convert to integers\n",
    "#using LabelEncoder() might not be best, sometimes better to manually set integers in order that makes sense\n",
    "df = pd.DataFrame({'col1': [2,4,1,5,6], \n",
    "                  'col2': [\"morning\",\"night\",\"afternoon\",\"morning\",\"night\"],\n",
    "                    'col3': [3,6,4,6,2]})\n",
    "df1 = df\n",
    "label_encoder = LabelEncoder()\n",
    "df1['col2'] = label_encoder.fit_transform(df1['col2'])\n",
    "df1\n",
    "\n",
    "#3. Create new column for each value of category column\n",
    "df_train = pd.DataFrame({'col1': [2,4,1,5,6], \n",
    "                  'col2': [\"red\",\"blue\",\"yellow\",\"blue\",\"red\"],\n",
    "                  'col3': [3,6,4,6,2],\n",
    "                  'col4': ['steel','wood','steel','wood','steel']})\n",
    "# Get list of categorical variables\n",
    "s = (df_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_df = pd.DataFrame(OH_encoder.fit_transform(df_train[object_cols]))\n",
    "#use OneHotEncoder.transform() on test data after just using OneHotEncoder.fit_transform() on train data\n",
    "#OH_cols_df = pd.DataFrame(OH_encoder.transform(df_test[object_cols]))\n",
    "OH_cols_df\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_df.index = df_train.index\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_df_train = df_train.drop(object_cols, axis=1)\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_df_train = pd.concat([num_df_train, OH_cols_df], axis=1)\n",
    "OH_df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0., 1., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 1.],\n",
       "       [6., 0., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame({'col1': [2,np.NaN,np.NaN,np.NaN,6], \n",
    "                  'col2': [\"red\",\"blue\",\"yellow\",\"blue\",\"red\"],\n",
    "                  'col3': [3,6,4,6,2],\n",
    "                  'col4': ['steel','wood','steel','wood','steel']})\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, ['col1']),\n",
    "        ('cat', categorical_transformer, ['col2','col4'])\n",
    "    ])\n",
    "x = preprocessor.fit_transform(df_train)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1627400. ,  857110. ,  617770. , ..., 1365232.5,  628900. ,\n",
       "        980400. ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use pipelines to shorthand preproccessing and modeling\n",
    "mel_df = mel_df[mel_df['Price'].notna()]\n",
    "mel_df.drop(['Address','Suburb','SellerG','Date'], axis=1) #drop columns for this example, for faster processing time\n",
    "y = mel_df['Price']\n",
    "x = mel_df.loc[:, mel_df.columns != 'Price']\n",
    "categorical_cols = ['Suburb','Type','Method','SellerG','Date','CouncilArea','Regionname']\n",
    "numerical_cols = ['Rooms','Distance','Postcode','Bedroom2','Bathroom','Car','Landsize','BuildingArea',\n",
    "                  'YearBuilt','Longtitude','Lattitude','Propertycount']\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, random_state = 0)\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(x_train, y_train)\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(x_valid)\n",
    "#calculate MAE\n",
    "mae = mean_absolute_error(preds, y_valid)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163714.06921944037"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation - using different parts of the data as train and validate\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = -1 * cross_val_score(my_pipeline, x, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1627400. ,  857110. ,  617770. , ..., 1365232.5,  628900. ,\n",
       "        980400. ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb            object\n",
       "Address           object\n",
       "                  ...   \n",
       "Regionname        object\n",
       "Propertycount    float64\n",
       "Length: 21, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
